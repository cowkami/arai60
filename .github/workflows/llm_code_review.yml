# .github/workflows/llm_code_review.yml

name: "LLM Code Review"

on:
  pull_request:
    types: [opened, synchronize]
    branches:
      - main

permissions:
  contents: read
  pull-requests: write

jobs:
  review:
    runs-on: ubuntu-latest
    steps:
      - name: "Checkout code"
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Fetch all history to get the diff

      - name: "Get code diff"
        id: get_diff
        run: |
          diff_output=$(git diff ${{ github.event.pull_request.base.sha }} ${{ github.event.pull_request.head.sha }})
          # Truncate very large diffs to keep within model limits.
          # Keep the first 20000 characters to provide useful context while avoiding oversized payloads.
          diff_output=$(python - <<'PY' <<< "$diff_output"
import sys
data = sys.stdin.read()
print(data[:20000])
PY
          )
          if [ -z "$diff_output" ]; then
            diff_output="(No changes detected in diff.)"
          fi
          echo "diff_content<<EOF" >> $GITHUB_OUTPUT
          echo "$diff_output" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: "Call LLM Reviewer (bash with curl)"
        id: llm_review
        run: |
          # Define OpenAI API details
          OPENAI_API_ENDPOINT="https://api.openai.com/v1/responses"
          OPENAI_MODEL="gpt-4o"

          # Construct the prompt
          PROMPT="You are an expert software engineer acting as a code reviewer.\n\nPlease analyze the provided diff and identify potential issues such as:\n- Bugs or logical errors\n- Performance issues\n- Security vulnerabilities\n- Violations of best practices or language idioms\n- Lack of clarity, comments, or documentation\n\nProvide your feedback in a structured Markdown format. If there are no issues, state that the code looks good.\n\nHere is the code diff to review:\n\`\`\`diff\n${DIFF_CONTENT}\n\`\`\`"

          # Create JSON payload for the Responses API
          PAYLOAD=$(jq -n \
            --arg model "$OPENAI_MODEL" \
            --arg prompt "$PROMPT" \
            '{
              "model": $model,
              "input": $prompt,
              "max_output_tokens": 1000,
              "temperature": 0.4
            }')

          # Make the API call using curl (capture body separately from status)
          HTTP_STATUS=$(curl -sS -w "%{http_code}" -o response.json -X POST \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer ${LLM_API_KEY}" \
            -d "$PAYLOAD" \
            "$OPENAI_API_ENDPOINT")

          if [ "$HTTP_STATUS" -lt 200 ] || [ "$HTTP_STATUS" -ge 300 ]; then
            REVIEW_CONTENT="Error: OpenAI API request failed with HTTP status ${HTTP_STATUS}."
          else
            # Extract the content from the response
            REVIEW_CONTENT=$(jq -r '[.output[]? | .content[]? | select(.type=="output_text") | .text] | join("\n")' response.json)
            if [ -z "$REVIEW_CONTENT" ] || [ "$REVIEW_CONTENT" = "null" ]; then
              REVIEW_CONTENT="Error: Could not parse LLM response."
            fi
          fi

          # Output the review content for the next step
          echo "review_content<<EOF" >> $GITHUB_OUTPUT
          echo "$REVIEW_CONTENT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
        env:
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }} # Securely stored API key
          DIFF_CONTENT: ${{ steps.get_diff.outputs.diff_content }}

      - name: "Post Review Comment"
        uses: actions/github-script@v6
        with:
          script: |
            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: `### ðŸ¤– LLM Code Review\n\n${{ steps.llm_review.outputs.review_content }}`
            })
